["","Welcome to Machine Learning! In this module, we introduce the core idea of teaching a computer to learn concepts using data—without being explicitly programmed. The Course Wiki is under construction. Please visit the resources tab for the most complete and up-to-date information.Linear regression predicts a real-valued output based on an input value. We discuss the application of linear regression to housing price prediction, present the notion of a cost function, and introduce the gradient descent method for learning.This course includes programming assignments designed to help you understand how to implement the learning algorithms in practice. To complete the programming assignments, you will need to use Octave or MATLAB. This module introduces Octave/Matlab and shows you how to submit an assignment.Logistic regression is a method for classifying data into discrete outcomes. For example, we might use logistic regression to classify an email  as spam or not spam. In this module, we introduce the notion of classification, the cost function for logistic regression, and the application of logistic regression to multi-class classification.\nNeural networks is a model inspired by how the brain works. It is widely used today in many applications: when your phone interprets and understand your voice commands, it is likely that a neural network is helping to understand your speech; when you cash a check, the machines that automatically read the digits also use neural networks. To optimize a machine learning algorithm, you’ll need to first understand where the biggest improvements can be made. In this module, we discuss how to understand the performance of a machine learning system with multiple parts, and also how to deal with skewed data.\nGiven a large number of data points, we may sometimes want to figure out which ones vary significantly from the average. For example, in manufacturing, we may want to detect defects or anomalies. We show how a dataset can be modeled using a Gaussian distribution, and how the model can be used for anomaly detection.\nWhen you buy a product online, most websites automatically recommend other products that you may like. Recommender systems look at patterns of activities between different users and different products to produce these recommendations. In this module, we introduce recommender algorithms such as the collaborative filtering algorithm and low-rank matrix factorization.The Leland Stanford Junior University, commonly referred to as Stanford University or Stanford, is an American private research university located in Stanford, California on an 8,180-acre (3,310 ha) campus near Palo Alto, California, United States.","While many machine learning algorithms have been around for a long time, the ability to automatically apply complex mathematical calculations to big data – over and over, faster and faster – is a recent development. Here are a few widely publicized examples of machine learning applications you may be familiar with:Most industries working with large amounts of data have recognized the value of machine learning technology. By gleaning insights from this data – often in real time – organizations are able to work more efficiently or gain an advantage over competitors.Data mining can be considered a superset of many different methods to extract insights from data. It might involve traditional statistical methods and machine learning. Data mining applies methods from many different areas to identify previously unknown patterns from data. This can include statistical algorithms, machine learning, text analytics, time series analysis and other areas of analytics. Data mining also includes the study and practice of data storage and data manipulation.The main difference with machine learning is that just like statistical models, the goal is to understand the structure of the data – fit theoretical distributions to the data that are well understood. So, with statistical models there is a theory behind the model that is mathematically proven, but this requires that data meets certain strong assumptions too. Machine learning has developed based on the ability to use computers to probe the data for structure, even if we do not have a theory of what that structure looks like. The test for a machine learning model is a validation error on new data, not a theoretical test that proves a null hypothesis. Because machine learning often uses an iterative approach to learn from data, the learning can be easily automated. Passes are run through the data until a robust pattern is found.To get the most value from machine learning, you have to know how to pair the best algorithms with the right tools and processes. SAS combines rich, sophisticated heritage in statistics and data mining with new architectural advances to ensure your models run as fast as possible – even in huge enterprise environments.Those driverless cars we keep hearing about from Google? They’re just one example of machine learning – and we’re about to hear of many more. Even though the concept of machine learning has been around for decades, it’s now becoming more pertinent to our daily lives because of increased amounts of data, cheaper storage and greater processing power.It discusses challenges and how to overcome them, presents a guide to machine-learning best practices and popular machine-learning algorithms,  and looks at how two organizations are exploiting machine learning for their analytic evolution.What happens when two increasingly popular technology concepts – machine learning and the Internet of Things – join forces? Mika Tanskanen, a manufacturing industry consultant in Finland, says the IoT can help machine learning reach even higher levels of efficiency.","This guide is intended to be accessible to anyone. Basic concepts in probability, statistics, programming, linear algebra, and calculus will be discussed, but it isn’t necessary to have prior knowledge of them to gain value from this series.Artificial intelligence will shape our future more powerfully than any other innovation this century. Anyone who does not understand it will soon find themselves feeling left behind, waking up in a world full of technology that feels more and more like magic.In everyday life, it’s increasingly commonplace to discover machines in roles traditionally occupied by humans. Really, don’t be surprised if a little housekeeping delivery bot shows up instead of a human next time you call the hotel desk to send up some toothpaste.In this series, we’ll explore the core machine learning concepts behind these technologies. By the end, you should be able to describe how they work at a conceptual level and be equipped with the tools to start building similar applications yourself.“It’s part of the history of the field of artificial intelligence that every time somebody figured out how to make a computer do something — play good checkers, solve simple but relatively informal problems — there was chorus of critics to say, ‘that’s not thinking’”Let an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any man however clever. Since the design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an ‘intelligence explosion,’ and the intelligence of man would be left far behind. Thus the first ultraintelligent machine is the last invention that man need ever make, provided that the machine is docile enough to tell us how to keep it under control. — I.J. Good, 1965Machine learning is at the core of our journey towards artificial general intelligence, and in the meantime, it will change every industry and have a massive impact on our day-to-day lives. That’s why we believe it’s worth understanding machine learning, at least at a conceptual level — and we designed this series to be the best place to start.Most of this series was written during a 10-day trip to the United Kingdom in a frantic blur of trains, planes, cafes, pubs and wherever else we could find a dry place to sit. Our aim was to solidify our own understanding of artificial intelligence, machine learning, and how the methods therein fit together — and hopefully create something worth sharing in the process.","","","","For Holgate, who came to Google almost four years ago with a degree in computer science and math, it’s a chance to master the hottest paradigm of the software world: using learning algorithms (“learners”) and tons of data to “teach” software to accomplish its tasks. For many years, machine learning was considered a specialty, limited to an elite few. That era is over, as recent results indicate that machine learning, powered by “neural nets” that emulate the way a biological brain operates, is the true path towards imbuing computers with the powers of humans, and in some cases, super humans. Google is committed to expanding that elite within its walls, with the hope of making it the norm. For engineers like Holgate, the ninja program is a chance to leap to the forefront of the effort, learning from the best of the best. “These people are building ridiculous models and have PhD’s,” she says, unable to mask the awe in her voice. She’s even gotten over the fact that she is actually in a program that calls its students “ninjas.” “At first, I cringed, but I learned to accept it,” she says.“The more people who think about solving problems in this way, the better we’ll be,” says a leader in the firm’s ML effort, Jeff Dean, who is to software at Google as Tom Brady is to quarterbacking in the NFL. Today, he estimates that of Google’s 25,000 engineers, only a “few thousand” are proficient in machine learning. Maybe ten percent. He’d like that to be closer to a hundred percent. “It would be great to have every engineer have at least some amount of knowledge of machine learning,” he says.These improved neural-net algorithms along with more powerful computation from the Moore’s Law effect and an exponential increase in data drawn from the behavior of huge numbers of users at companies like Google and Facebook, began a new era of ascendant machine learning. Giannandrea joined those who believed it should be central to the company. That cohort included Dean, co-founder of the Google Brain , a neural net project originating in the company’s long-range research division Google X. (Now known simply as X.)Google’s bear-hug-level embrace of machine learning does not simply represent a shift in programming technique. It’s a serious commitment to techniques that will bestow hitherto unattainable powers to computers. The leading edge of this are “deep learning” algorithms built around sophisticated neural nets inspired by brain architecture. Google Brain is a deep learning effort, and DeepMind, the AI company Google bought for a reported $500 million in January 2014, also concentrates on that end of the spectrum. It was DeepMind that created the AlphaGo system that beat a champion of Go, shattering expectations of intelligent machine performance and sending ripples of concern among those fearful of smart machines and killer robots.While Giannandrea dismisses the “AI-is-going-to-kill us” camp as ill-informed Cassandras, he does contend that machine learning systems are going to be transformative, in everything from medical diagnoses to driving our cars. While machine learning won’t replace humans, it will change humanity.That understanding hadn’t yet hit in 2012 when Giannandrea had the idea to “get a bunch of people who were doing this stuff” and put them in a single building. Google Brain, which had “graduated” from the X division, joined the party. “We uprooted a bunch of teams, put them in a building, got a nice new coffee machine,” he says. “People who previously had just been working on what we called perception — sound and speech understanding and so on — were now talking to the people who were trying to work on language.”Google boosted the odds by keeping Corrado and his team in close and constant contact with the Gmail group, an approach that is increasingly common as machine learning experts fan out among product groups. “Machine learning is as much art as it is science,” says Corrado. “It’s like cooking — yes, there’s chemistry involved but to do something really interesting, you have to learn how to combine the ingredients available to you.”When the team began testing Smart Reply, though, users noted a weird quirk: it would often suggest inappropriate romantic responses. “One of the failure modes was this really hysterical tendency for it to say, ‘I love you’ whenever it got confused,” says Corrado. “It wasn’t a software bug — it was an error in what we asked it to do.” The program had somehow learned a subtle aspect of human behavior: “If you’re cornered, saying, ‘I love you’ is a good defensive strategy.” Corrado was able to help the team tamp down the ardor.Smart Reply is only one data point in a dense graph of instances where ML has proved effective at Google. But perhaps the ultimate turning point came when machine learning became an integral part of search, Google’s flagship product and the font of virtually all its revenues. Search has always been based on artificial intelligence to some degree. But for many years, the company’s most sacred algorithms, those that delivered what were once known as the “ten blue links” in response to a search query, were deemed too important for ML’s learning algorithms. “Because search is such a large part of the company, ranking is very, very highly evolved, and there was a lot of skepticism you could move the needle very much,” says Giannandrea.In part this was a cultural resistance — a stubborn microcosm of the general challenge of getting control-freaky master hackers to adopt the Zen-ish machine learning approach. Amit Singhal, the long-time maester of search, was himself an acolyte of Gerald Salton, a legendary computer scientist whose pioneering work in document retrieval inspired Singhal to help revise the grad-student code of Brin and Page into something that could scale in the modern web era. (This put him in the school of “retrievers.”) He teased amazing results from those 20th century methods, and was suspicious of integrating learners into the complicated system that was Google’s lifeblood. “My first two years at Google I was in search quality, trying to use machine learning to improve ranking,” says David Pablo Cohn. “It turns out that Amit’s intuition was the best in the world, and we did better by trying to hard code whatever was in Amit’s brain. We couldn’t find anything as good as his approach.”By early 2014, Google’s machine learning masters believed that should change. “We had a series of discussions with the ranking team,” says Dean. “We said we should at least try this and see, is there any gain to be had.” The experiment his team had in mind turned out to be central to search: how well a document in the ranking matches a query (as measured by whether the user clicks on it). “We sort of just said, let’s try to compute this extra score from the neural net and see if that’s a useful score.”It turned out the answer was yes, and the system is now part of search, known as RankBrain. It went online in April 2015. Google is characteristically fuzzy on exactly how it improves search (something to do with the long tail? Better interpretation of ambiguous requests?) but Dean says that RankBrain is “involved in every query,” and affects the actual rankings “probably not in every query but in a lot of queries.” What’s more, it’s hugely effective. Of the hundreds of “signals” Google search uses when it calculates its rankings (a signal might be the user’s geographical location, or whether the headline on a page matches the text in the query), RankBrain is now rated as the third most useful.But since academic programs are not yet producing ML experts in huge numbers, retraining workers is a necessity. And that isn’t always easy, especially at a company like Google, with many world-class engineers who have spent a lifetime achieving wizardry through traditional coding.Machine learning requires a different mindset. People who are master coders often become that way because they thrive on the total control that one can have by programming a system. Machine learning also requires a grasp of certain kinds of math and statistics, which many coders, even gonzo hackers who can zip off tight programs of brobdingnagian length, never bothered to learn.It also requires a degree of patience. “The machine learning model is not a static piece of code — you're constantly feeding it data,” says Robson. “We are constantly updating the models and learning, adding more data and tweaking how we're going to make predictions. It feels like a living, breathing thing. It’s a different kind of engineering.”“It’s a discipline really of doing experimentation with the different algorithms, or about which sets of training data work really well for your use case,” says Giannandrea, who despite his new role as search czar still considers evangelizing machine learning internally as part of his job. “The computer science part doesn’t go away. But there is more of a focus on mathematics and statistics and less of a focus on writing half a million lines of code.”While Google takes pains to couch the move as an altruistic boon to the community, it also acknowledges that a new generation of programmers familiar with its in-house machine learning tools is a pretty good thing for Google recruiting. (Skeptics have noted that Google’s open-sourcing TensorFlow is a catch-up move with Facebook, which publicly released deep-learning modules for an earlier ML system, Torch, in January 2015.) Still, TensorFlow’s features, along with the Google imprimatur, have rapidly made it a favorite in ML programming circles. According to Giannandrea, when Google offered its first online TensorFlow course, 75,000 people signed up.But since Google’s biggest need is people to design and refine these systems, just as the company is working feverishly to refine its software-training tools, it’s madly honing its experiments in training machine-learning engineers. They range from small to large. The latter category includes quick-and-dirty two-day “Machine Learning Crash Course with TensorFlow,” with slides and exercises. Google hopes this is a first taste, and the engineers will subsequently seek out resources to learn more. “We have thousands of people signed up for the next offering of this one course,” says Dean.Other, smaller efforts draw outsiders into Google’s machine learning maw. Earlier this spring, Google began the Brain Residency program, a program to bring in promising outsiders for a year of intense training from within the Google Brain group. “We’re calling it a jump start in your Deep Learning career,” says Robson, who helps administer the program. Though it’s possible that some of the 27 machine-learning-nauts from different disciplines in the initial program might wind up sticking around Google, the stated purpose of the class is to dispatch them back in the wild, using their superpowers to spread Google’s version of machine learning throughout the data-sphere.Her program began with a four-week boot camp where the product leads of Google’s most advanced AI projects drilled them on the fine points of baking machine learning into projects. “We throw the ninjas into a conference room and Greg Corrado is there at the white board, explaining LSTM [“Long Short Term Memory,” a technique that makes powerful neural nets], gesturing wildly, showing how this really works, what the math is, how to use it in production,” says Robson. “We basically just do this with every technique we have and every tool in our toolbox for the first four weeks to give them a really immersive dive.”Holgate has survived boot camp and now is using machine learning tools to build a communications feature in Android that will help Googlers communicate with each other. She’s tuning hyperparameters. She’s cleansing her input data. She’s stripping out the stop words. But there’s no way she’s turning back, because she knows that these artificial intelligence techniques are the present and the future of Google, maybe of all technology. Maybe of everything.","As technology, and, importantly, our understanding of how our minds work, has progressed, our concept of what constitutes AI has changed. Rather than increasingly complex calculations, work in the field of AI concentrated on mimicking human decision making processes and carrying out tasks in ever more human ways.Artificial Intelligences – devices designed to act intelligently – are often classified into one of two fundamental groups – applied or general. Applied AI is far more common – systems designed to intelligently trade stocks and shares, or manoeuvre an autonomous vehicle would fall into this category.Generalized AIs – systems or devices which can in theory handle any task – are less common, but this is where some of the most exciting advancements are happening today. It is also the area that has led to the development of Machine Learning. Often referred to as a subset of AI, it’s really more accurate to think of it as the current state-of-the-art.","After all, you’re teaching machines that work in ones and zeros to reach their own conclusions about the world. You’re teaching them how to think! However, it’s not nearly as hard as the complex and formula-laden literature would have you believe.Like all of the best frameworks we have for understanding our world, e.g. Newton’s Laws of Motion, Jobs to be Done, Supply & Demand — the best ideas and concepts in machine learning are simple. The majority of literature on machine learning, however, is riddled with complex notation, formulae and superfluous language. It puts walls up around fundamentally simple ideas.We achieved all of this with less than 40 lines of code, and some simple algorithms that can be described in a blog post. However, you would never know how simple some of these ideas are from reading academic literature. Here’s an excerpt from the paper introducing K-Means (it’s hard to pinpoint the exact first introduction of K-Means, but this was the first paper to use the term “K-Means”):Want to suggest tags in your project management app? Or assignees in your customer support tool? Or members of a group on a social network? The chances are some simple code, and an easy algorithm will get there. So, when faced with a challenge in your product where you believe machine learning can help, don’t be discouraged."," You can use the ML model to get predictions on new data for which you do not know\n                        the\n                        target. For example, let's say that you want to train an ML model to predict if an\n                        email is spam\n                        or not spam. You would provide Amazon ML with training data that contains emails for\n                        which you know\n                        the target (that is, a label that tells whether an email is spam or not spam). Amazon\n                        ML would train\n                        an ML model by using this data, resulting in a model that attempts to predict whether\n                        new email\n                        will be spam or not spam. \n                     "]